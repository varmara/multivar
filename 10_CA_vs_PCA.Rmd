---
title: "Корреспондентный анализ и анализ главных компонент"
subtitle: "Анализ и визуализация многомерных данных с использованием R"
author: Вадим Хайтов, Марина Варфоломеева
presenters: [{
  name: 'Вадим Хайтов',
  company: 'Каф. Зоологии беспозвоночных, СПбГУ',
  }]
output:
 ioslides_presentation:
  widescreen: true
  css: assets/my_styles.css
  logo: assets/Linmod_logo.png
---


```{r setup, include = FALSE, cache = FALSE, purl = FALSE}
# output options
options(width = 70, scipen = 6, digits = 3)
library(knitr)
# chunk default options
opts_chunk$set(fig.align='center', tidy = FALSE, fig.width = 7, fig.height = 3, warning = FALSE)
```

```{r, libs-funs, echo=FALSE}
library(ggplot2)
library(grid)
theme_set(theme_bw(base_size = 16) + theme(legend.key = element_blank()))
update_geom_defaults("point", list(shape = 19, size = 4))
library(gridExtra)
```

## Корреспондентрый анализ и анализ главных компонент

- Сложности при анализе видового состава сообществ при помощи анализа главных компонент
    - Анализ сырых данных
    - Трансформация Хеллингера
    - Расстояние хорды

- Корреспондентный анализ
    - Анализ таблиц сопряженности, хи-квадрат
    - Оси в корреспондентном анализе
    - Интерпретация графиков в корреспондентном анализе

### Вы сможете

- Избавляться от "эффекта подковы" в анализе главных компонент при помощи трансформаций данных
- Проводить корреспондентный анализ таблиц сопряженности
- Объяснить, что именно означает взаиморасположение точек объектов и переменных на графиках результатов корреспондентного анализа
- Интерпретировать графики результатов корреспондентного анализа


# Анализ видового состава сообществ. Трансформации данных


## Пример: Птицы в лесах Австралии

Обилие 102 видов птиц в 37 сайтах в юго-восточной Австралии (Mac Nally, 1989; данные из Quinn, Keough, 2002). Можно ли описать отношения между сайтами небольшим числом главных компонент?

```{r}
library(readxl)
birds <- read_excel(path = "data/macnally.xlsx")
str(birds)
```

##

```{r}
# названия переменных
colnames(birds)
```

##

```{r}
# имена переводим в нижний регистр
colnames(birds) <- tolower(colnames(birds))
# есть ли пропущенные значения
any(!complete.cases(birds))
```


## Задание: Проведите анализ главных компонент


## Результаты анализа главных компонент

```{r fig.height=4, message=FALSE}
library(vegan)
bird_pca <- rda(birds[ , -c(1, 2)], scale = TRUE)
# summary(bird_pca)
screeplot(bird_pca, type = "lines", bstick = TRUE) # график собственных чисел
```

> - Первые две компоненты объясняют умеренное количество изменчивости


## Факторные нагрузки

```{r fig.height=4}
biplot(bird_pca, display = "species", scaling = 2, type = "t")
```

> - У многих переменных факторные нагрузки велики сразу на две оси. Это может быть неудобно.

## Обратите внимание, график в виде подковы!

Сайты 29 и 14 на самом деле расположены далеко друг от друга и мало похожи. Почему же они сближены на графике?

```{r fig.height=4}
biplot(bird_pca, display = "sites", scaling = 1) # биплот расстояний
```

> - Так происходит от того, что завышены корреляции между переменными из-за большого числа нулей


## Чтобы исчез "эффект подковы" нужна трансформация исходных данных

- Стандартизация Хеллингера (Hellinger distance)
- хордальное расстояние (chord distance)

```{r}
birds_h <- decostand(birds[ , -c(1, 2)], method =  "hellinger") # Стандартизация Хеллингера
birds_ch <- decostand(birds[ , -c(1, 2)], method ="normalize") # Использование хордального расстояния
```

Задание: Выясните в чем суть этих преобразований.


## Задание: Проведите анализ главных компонент по трансформированным данным

Сравните долю дисперсии, объясненной первыми двумя компонентами с результатами анализа нетрансформированных данных.

- В каком случае объясненная дисперсия больше?

Сравните получившиеся ординации объектов.

- Исчез ли "эффект подковы" после трансформации?
- Изменилась ли группировка объектов?

## Анализ главных компонент

```{r}
bird_h_pca <- rda(birds_h)
summary(bird_h_pca)
```


## Собственные числа

```{r fig.height=5}
screeplot(bird_h_pca, bstick = TRUE)
```



## Ординация до и после трансформации данных

```{r fig.width = 10, fig.height = 4.5, fig.show='hold'}
op <- par(mfrow = c(1, 3), cex = 0.9, mar = c(4, 4, 2.5, 0.5))
biplot(bird_pca, display = "sites", scaling = 1, main = "PCA,\nбез трансформации")
plot(procrustes(bird_h_pca, bird_pca), main = "Прокрустово\nпреобразование")
biplot(bird_h_pca, display = "sites", scaling = 1, main = "PCA,\nтрансформация Хеллингера")
par(op)
```

## Для успешного применения анализа главных компонент нужно:

- Линейные связи между переменными (т.к. матрица корреляций или ковариаций)
- Исключить наблюдения, в которых есть пропущенные значения
- Если много нулей - трансформация данных
- Если очень много нулей - удалить такие переменные из анализа


## Пример: Крысы

Число грызунов разных видов в нескольких сайтах в южной Калифорнии (Bolger et al. 1997). Некоторые из этих сайтов оказались изолированы из-за урбанизации. Кроме того, несколько сайтов в исследовании из нефрагментированной местности.

```{r}
rats <- read.csv("data/bolger1.csv")
head(rats, 2)
# имена переводим в нижний регистр
colnames(rats) <- tolower(colnames(rats))
# есть ли пропущенные значения
any(!complete.cases(rats))
```

<div class = "footnote">Данные из Quinn, Keough, 2002</div>


## Задание: проведите анализ главных компонент

- Используйте хордальное расстояние
- Нарисуйте биплот расстояний

##

```{r fig.show='hold', fig.height=4}
rats_ch <- decostand(rats[ , -c(1, 2)], "norm") # chord distance
rats_ch_pca <- rda(rats_ch)
# summary(rats_ch_pca)
op <- par(mfrow = c(1, 2))
screeplot(rats_ch_pca, bstick = TRUE, main = "График собственных чисел")
biplot(rats_ch_pca, scaling = "symmetric", main = "PCA, хордальное расстояние")
par(op)
```

## Общие проблемы в двух примерах

1. Проявляется эффект подковы: непохожие объекты сближены на ординации.
2. Нет однзначной связи главных компонент и исходных признаков: трудно дать тратовку компонентам.
3. Преобразования не помогают избежать проблем.

**Выход:** 
1. Перейти к nMDS и непрямым методам трактовки ординации.
2. Изменить логику анализа - отказаться от эвклидовой метрики, на которой основан PCA. Это позволяет сделать корреспондентный анализ.  




# Таблицы сопряженности 

## Анализ таблиц сопряженности

Корреспондентный анализ был придуман для анализа сводных таблиц  
вроде этой:

| Горох | Желтый | Зеленый |
| ---- | ---- | ---- |
| Гладкий | 99 | 42 |
| Морщинистый | 29 | 13 |



## Ожидаемые частоты

Таблица наблюдаемых частот

| Горох | Желтый | Зеленый | Сумма |
| ---- | ---- | ---- | ---- |
| Гладкий | __99__ | 42 | __141__ |
| Морщинистый | 29 | 13 | __42__ |
| Сумма | __128__ | __55__ | __183__ |

Ожидаемая частота (количество горошин) желтого и гладкого, если эти признаки независимы:

вероятность быть желтым $\times$ вероятность быть гладким  $\times$ общее число горошин

$$\frac {141} {183} \times \frac{128} {183} \times 183 = \frac {141 \times 128} {183} = 98.6$$



## Можно посчитать ожидаемые частоты в каждой ячейке

Таблица наблюдаемых частот

| Горох | Желтый | Зеленый | Сумма |
| ---- | ---- | ---- | ---- |
| Гладкий | __99__ | 42 | __141__ |
| Морщинистый | 29 | 13 | __42__ |
| Сумма | __128__ | __55__ | __183__ |

Ожидаемая частота желтого и гладкого, если эти признаки независимы:

вероятность быть желтым $\times$ вероятность быть гладким  $\times$ общее число горошин

$$\frac {141} {183} \times \frac{128} {183} \times 183 = \frac {141 \times 128} {183} = 98.6$$


Таблица ожидаемых частот

| Горох | Желтый | Зеленый |
| ---- | ---- | ---- |
| Гладкий | 98.6 | 42.4 |
| Морщинистый | 29.4 | 12.6 |



## Проверяем гипотезу о независимости столбцов и строк

Таблица наблюдаемых частот

| Горох | Желтый | Зеленый | Сумма |
| ---- | ---- | ---- | ---- |
| Гладкий | __99__ | 42 | __141__ |
| Морщинистый | 29 | 13 | __42__ |
| Сумма | __128__ | __55__ | __183__ |

Таблица ожидаемых частот

| Горох | Желтый | Зеленый |
| ---- | ---- | ---- |
| Гладкий | 98.6 | 42.4 |
| Морщинистый | 29.4 | 12.6 |

> - Если столбцы и строки независимы, то наблюдаемые частоты не будут отличаться от ожидаемых
> - Для каждой ячейки: $\chi ^2 = \frac{(O - E)^2}{E}$ 
> - Общий хи-квадрат - это сумма по таблице $\chi ^2 = \sum{\chi^2_{ij}}$


# Корреспондентный анализ

__хи-квадрат - это мера независимости переменных (строк и столбцов)__

Корреспондентный анализ помогает визуализировать матрицу хи-квадратов, если переменных очень много

Механика похожа на анализ главных компонент (вернее, SVD - singular value decomposition)

Вместо столбцов и строк исходных данных получатся новые переменные - главные оси (principal axes)


## Свойства главных осей

- Главные оси независимы друг от друга (перпендикулярны)
- Каждая последующая объясняет меньше общей инерции (общего хи-квадрат, а не изменчивости!!!)
- Всего осей может быть не больше чем минимальное из этих значений: (число строк - 1), (число столбцов - 1)
- Первая ось - переменные, которые объясняют максимум зависимости строк от столбцов (значения которых сильнее всего отличаются от ожидаемых для данных объектов)
- Результаты изображаются в виде точечных графиков, похожих на биплоты (осторожно, scaling!)


## Корреспондентный анализ данных про крыс

```{r}
rats_ca <- cca(rats[ , -c(1, 2)])
summary(rats_ca)
```


## Сколько общей инерции объясняют первые две главных оси?

```{r}
eig <- eigenvals(rats_ca)
eig/sum(eig)*100
cumsum(eig)/sum(eig)*100
```


## Сколько главных осей достаточно?

```{r}
screeplot(rats_ca, type = "lines", bstick = TRUE)
```


## Scaling

Разные варианты scaling не меняют порядок расположения, но меняют расстояния между объектами.

scaling 1 или "sites" (для графиков "объектов")
- расстояния между объектами пропорциональны хи-квадрату

scaling 2 или "species" (для графиков "переменных")
- расстояния между переменными пропорциональны хи-квадрату

scaling 3 или "symmetric" (компромиссный вариант)
- нечто среднее между 1 и 2



## Как трактовать биплот в случае CA

- Если объект и переменная расположены рядом, то у этого объекта значение переменной выше ожидаемого при условии независимости объектов и переменных.
- Если объект и переменная расположены далеко, то у этого объекта значение переменной ниже ожидаемого.

```{r fig.height=4}
plot(rats_ca, scaling = "sites")
```





## Создаем функцию, чтобы быстрее рисовать цветные графики

```{r tidy=TRUE}
col_ord_plot <- function(ord, scaling = 1, colvec = NULL, colfac, pch = 21, lab.cex = 1, leg.cex = 0.9, leg.pos = "bottom", ncol = 1, display.labs = TRUE, display.legend = TRUE, ...){
  if(is.null(colvec)){ # создаем вектор цветов
  ncolours <- length(levels(colfac))
  colvec <- rainbow(ncolours, s = 0.8, v = 0.9)
  }
  plot(ord, type = "n", scaling = scaling, ...) # пустой график
  # точки, раскрашенные по уровням фактора
  points(ord, display = "sites", scaling = scaling, pch = pch,
         col = colvec[colfac], bg = colvec[colfac], ...)
  if(display.labs == TRUE){ # подписи переменных
  text(ord, display = "species", scaling = scaling, cex = lab.cex)
  }
  if(display.legend == TRUE) { # легенда
  legend(x = leg.pos, legend = levels(colfac), bty = "n", pch = pch, 
         col = colvec, pt.bg = colvec, cex = leg.cex, ncol = ncol)
  }
}
```


## Графики PCA и CA

```{r ratplots, fig.show='hold', fig.height=4}
op <- par(mfrow = c(1, 3), mar = c(4, 4, 2, 1), cex = 0.9)

biplot(rats_ch_pca, scaling = 1, main = "biplot PCA")

col_ord_plot(ord = rats_ch_pca, colvec = c("steelblue", "red2"), 
             colfac = rats$type, leg.pos = "topleft", main = "PCA")
col_ord_plot(ord = rats_ca, colvec = c("steelblue", "red2"), 
             colfac = rats$type, leg.pos = "topleft", main = "CA")
par(op)
```



## График CA {.columns-2}

```{r echo=FALSE, fig.width=5.5, fig.height=6}
col_ord_plot(ord = rats_ca, colvec = c("steelblue", "red2"), 
             colfac = rats$type, leg.pos = "topleft", main = "CA")
```

- На графике CA видно, что в нескольких местах больше _R.rattus_ и _M.musculus_, чем ожидается (это интродуценты).
- В нескольких (других) сайтах сильно различаются наблюдаемые и ожидаемые численности "родных" видов.
- Сайты с нефрагментированной территории располагаются вперемешку с сайтами с фрагментированной территории.
- Эффект "дуги" (так называется "эффект подковы" для CA) не заметен, т.к. экологический градиент, видимо, оказался довольно коротким.


## Задание: Проведите корреспондентный анализ данных про птиц

- исчез ли эффект подковы?

## Решение

```{r fig.show='hold', tidy=TRUE, fig.height=3.5, fig.width=10}
bird_ca <- cca(birds[ , -c(1, 2)])
op <- par(mfrow = c(1, 2), mar = c(4, 4, 0, 0.5))
col_ord_plot(ord = bird_h_pca, colfac = factor(birds$habitat), leg.pos = "bottomleft", ncol = 1, display.labs = FALSE)
col_ord_plot(ord = bird_ca, colfac = factor(birds$habitat), leg.pos = "bottomleft", ncol = 1, display.labs = FALSE)
par(op)
```

> - Остался "эффект дуги" (так называется "эффект подковы" для корреспондентного анализа)


## Take home messages

- Анализ главных компонент
    - При анализе счетных признаков трансформация данных нужна, чтобы избежать "эффекта подковы"
- Корреспондентный анализ
    - придуман для анализа таблиц сопряженности
    - использует расстояние хи-квадрат
    - собственные числа отражают хи-квадрат, объясненный осями (степень зависимости столбцов и строк)
  

## Дополнительные ресурсы

- Borcard, D., Gillet, F., Legendre, P., 2011. Numerical ecology with R. Springer.
- Legendre, P., Legendre, L., 2012. Numerical ecology. Elsevier.
- Oksanen, J., 2011. Multivariate analysis of ecological communities in R: vegan tutorial. R package version 2–0.
- The Ordination Web Page URL http://ordination.okstate.edu/ (accessed 10.21.13).
- Quinn, G.G.P., Keough, M.J., 2002. Experimental design and data analysis for biologists. Cambridge University Press.
- Zuur, A.F., Ieno, E.N., Smith, G.M., 2007. Analysing ecological data. Springer.
